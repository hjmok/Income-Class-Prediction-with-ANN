{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Income Class Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S3G6Ey-sj4_"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "lUEnao1ns1yg",
        "outputId": "ee1620d9-a34c-4de1-b3fd-539866f85ea0"
      },
      "source": [
        "df = pd.read_csv('income.csv')\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>workclass</th>\n",
              "      <th>occupation</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>income</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>Male</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Private</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>50</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59</td>\n",
              "      <td>Male</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Self-emp</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>20</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38</td>\n",
              "      <td>Female</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>57</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64</td>\n",
              "      <td>Female</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Private</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>60</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>33</td>\n",
              "      <td>Male</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married</td>\n",
              "      <td>Private</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>40</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Married</td>\n",
              "      <td>Private</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>55</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>32</td>\n",
              "      <td>Female</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Private</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>40</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>33</td>\n",
              "      <td>Male</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married</td>\n",
              "      <td>Self-emp</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>60</td>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age     sex     education  ...  hours-per-week income label\n",
              "0       27    Male       HS-grad  ...              40  <=50K     0\n",
              "1       47    Male       Masters  ...              50   >50K     1\n",
              "2       59    Male       HS-grad  ...              20  <=50K     0\n",
              "3       38  Female   Prof-school  ...              57   >50K     1\n",
              "4       64  Female          11th  ...              40  <=50K     0\n",
              "...    ...     ...           ...  ...             ...    ...   ...\n",
              "29995   45    Male       Masters  ...              60   >50K     1\n",
              "29996   33    Male       HS-grad  ...              40   >50K     1\n",
              "29997   47    Male   Prof-school  ...              55   >50K     1\n",
              "29998   32  Female  Some-college  ...              40  <=50K     0\n",
              "29999   33    Male    Assoc-acdm  ...              60   >50K     1\n",
              "\n",
              "[30000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFABXoTWtSDW",
        "outputId": "0cc2063c-b43b-434d-ec73-8a5458a189ea"
      },
      "source": [
        "df['label'].value_counts() #21700 cases of class 0 (under 50k) and 8300 cases of class 1 (over 50k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    21700\n",
              "1     8300\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONMMBJIJuIMg"
      },
      "source": [
        "# **Part 1: Data Preprocessing**\r\n",
        "1.1 Separating Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyxK6J2vto5Y"
      },
      "source": [
        "categorical_col = ['sex', 'education', 'marital-status','workclass', 'occupation'] #categorical columns\r\n",
        "continuous_col = ['age','hours-per-week'] #continuous columns\r\n",
        "y_col = ['label'] #this will be the answer that we want to be the output of our NN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZuHTZUurYj",
        "outputId": "1b1c8e8e-c5b4-4ee7-9dd5-ffeba1ab6bd9"
      },
      "source": [
        "df.dtypes #notice the categorical columns are objects, but we want to convert them into categoires"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                int64\n",
              "sex               object\n",
              "education         object\n",
              "education-num      int64\n",
              "marital-status    object\n",
              "workclass         object\n",
              "occupation        object\n",
              "hours-per-week     int64\n",
              "income            object\n",
              "label              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0DxS7_muydR",
        "outputId": "f77b2426-dc74-43c7-e569-5d4c64dfcee9"
      },
      "source": [
        "for cat in categorical_col:\r\n",
        "  #looping through the categorical_col list so we can convert each column listed into a category datatype\r\n",
        "  df[cat] = df[cat].astype('category')\r\n",
        "\r\n",
        "df.dtypes #notice they are categories now"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                  int64\n",
              "sex               category\n",
              "education         category\n",
              "education-num        int64\n",
              "marital-status    category\n",
              "workclass         category\n",
              "occupation        category\n",
              "hours-per-week       int64\n",
              "income              object\n",
              "label                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4x5VVTju5XY",
        "outputId": "addec72d-ed54-4d43-b724-7bbdc0555ca5"
      },
      "source": [
        "df['education'].head() #notice the marital status column is has 6 categories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        HS-grad\n",
              "1        Masters\n",
              "2        HS-grad\n",
              "3    Prof-school\n",
              "4           11th\n",
              "Name: education, dtype: category\n",
              "Categories (14, object): ['10th', '11th', '12th', '5th-6th', ..., 'HS-grad', 'Masters',\n",
              "                          'Prof-school', 'Some-college']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqbQTWgKv6BB",
        "outputId": "a13e3a67-4bab-4b38-c3f3-da4e02054723"
      },
      "source": [
        "print(df['education'].cat.codes.values) #so we're given a code for each education level\r\n",
        "print(df['sex'].cat.codes.values) #so we're given a code for male = 0, female = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 11 10 ... 12 13  6]\n",
            "[1 1 1 ... 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK3yP4mzvL9r",
        "outputId": "8ff7db51-edf8-4542-85e2-5afefd8efaaf"
      },
      "source": [
        "cats = np.stack([df[col].cat.codes.values for col in categorical_col], axis = 1) #so we're stacking the arrays together along the y-axis to make a row for each\r\n",
        "cats = torch.tensor(cats, dtype = torch.int64) #converting our categories into a PyTorch Tensor to feed into our model\r\n",
        "\r\n",
        "cats #first row is male, HS-grad, Never-Married, Private, Craft-repair with their respective encoded values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 10,  3,  2,  1],\n",
              "        [ 1, 11,  1,  1,  2],\n",
              "        [ 1, 10,  0,  3,  7],\n",
              "        ...,\n",
              "        [ 1, 12,  1,  2,  7],\n",
              "        [ 0, 13,  3,  2,  0],\n",
              "        [ 1,  6,  1,  3,  2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I5qIC62xVaH"
      },
      "source": [
        "1.2 Separating Continuous Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FVC7kOowyEt",
        "outputId": "6882a2c4-80da-4e94-f153-103e0df5d8da"
      },
      "source": [
        "conts = np.stack([df[col].values for col in continuous_col], axis = 1) #doing what we did above to categorical value\r\n",
        "conts = torch.tensor(conts, dtype=torch.float) #converting our continous variables into a PyTorch Tensor feed into our model\r\n",
        "\r\n",
        "conts #first row is age 27 and 40 hours worked"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[27., 40.],\n",
              "        [47., 50.],\n",
              "        [59., 20.],\n",
              "        ...,\n",
              "        [47., 55.],\n",
              "        [32., 40.],\n",
              "        [33., 60.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhGyfWRrxxyp"
      },
      "source": [
        "1.3 Separating Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN1EgxIJxp3U",
        "outputId": "43270498-088e-4ed9-86e1-aef51aabcb48"
      },
      "source": [
        "y = torch.tensor(df[y_col].values).flatten() \r\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0,  ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLkT-Lcux3dA",
        "outputId": "e18780ee-b359-4d7d-97a8-6d99fd0d268c"
      },
      "source": [
        "print('cats.shape =',cats.shape)\r\n",
        "print('conts.shape =',conts.shape)\r\n",
        "print('y.shape =',y.shape)\r\n",
        "#shapes are as expected with 5 columns in categorical, 2 columns in continuous, and 1 column as the label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats.shape = torch.Size([30000, 5])\n",
            "conts.shape = torch.Size([30000, 2])\n",
            "y.shape = torch.Size([30000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVuTBWmTRqxv"
      },
      "source": [
        "1.4 Embedding our Categories (One Hot Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0eb7GB7x-rD",
        "outputId": "c1d4db5d-f401-4721-9603-3c29c61aa7e1"
      },
      "source": [
        "categorical_sizes = [len(df[col].cat.categories) for col in categorical_col] #category sizes\r\n",
        "categorical_sizes #so sex has 2 classes, education has 14, marital has6, work class has 5, and occupation has 12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 14, 6, 5, 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmGa_IAfygOY",
        "outputId": "8da0eff3-cdf8-48ab-dd06-57c2d50db91a"
      },
      "source": [
        "emb_sizes = [(size, min(50, (size+1)//2)) for size in categorical_sizes] #so for size [2, 14, 6, 5, 12] in categorical_sizes, embed 50 or take the size and divide by 2\r\n",
        "#the +1 is incase we only have 2 categories and // is to make sure the output is an integer\r\n",
        "emb_sizes #none of the sizes exceeded 50, so it just made the embedding size the size divided by 2. \r\n",
        "#so here, our number of categories are [2, 14, 6, 5, 12] and our embedding sizes are 1,7,3,3,6\r\n",
        "\r\n",
        "#So the embedding provides a more compact (lower dimensional) representation of a set of input variables that have some correlations. It's useful because it reduces the number of parameters overall. \r\n",
        "#So technically we could've just used all 2+14+6+5+12 as inputs into our NN, but we used embedding to reduce the parameters and make calculations faster\r\n",
        "#An embedding layer simply maps/projects some N dimensional tensor into another number of dimensions, the number of dimensions to output to are often arbitrary, but you can have some logic to it, like embedding marital status to 2 dimensions may end up mapping closely to single vs not single or workclass to 2 dimensions could give government vs private (although there is no guarantee of this)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 1), (14, 7), (6, 3), (5, 3), (12, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSwBB0jC6RC"
      },
      "source": [
        "# **Part 2: Creating the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PoMvXtu0LgR"
      },
      "source": [
        "#Inheriting from nn.Module to use it's features\r\n",
        "class Model(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, emb_sizes, n_continuous, out_size, n_layers, p=0.5):\r\n",
        "    #so our parameters are embedding size, number of continous features, output size, number of layers, and our dropout probability defaulted to 50%\r\n",
        "    #This determins how many layers are there in our NN\r\n",
        "\r\n",
        "    super().__init__() #inheriting the features from nn.Module\r\n",
        "    self.embeds = nn.ModuleList([nn.Embedding(num_embeddings = ni, embedding_dim = nf) for ni,nf in emb_sizes]) #so now our ModuleList is filled with the Embedding layers (one for hour, one of ampm, and one for weekday)\r\n",
        "    self.emb_drop = nn.Dropout(p) #adding a dropout layer\r\n",
        "    self.bn_cont = nn.BatchNorm1d(n_continuous) #normalizing the continous data so it falls within the same order of magnitude range\r\n",
        "\r\n",
        "    layerlist = [] #initializing layerlist so we can store our layers\r\n",
        "    n_emb = sum([nf for ni,nf in emb_sizes]) #calculating the number of embeddings, which is basically 12 + 1 + 4\r\n",
        "    n_in = n_emb + n_continuous #so the total number of inputs will be the number of embeddings plus the number of continous features\r\n",
        "\r\n",
        "    for i in n_layers:\r\n",
        "      layerlist.append(nn.Linear(n_in, i)) #create a layer connecting n_in and i, where i is the number of neurons. Basically this makes a fully connected layer. \r\n",
        "      layerlist.append(nn.ReLU(inplace = True)) #adding the activation function to the layer\r\n",
        "      layerlist.append(nn.BatchNorm1d(i)) #adding the normalization of the continuous values to the list\r\n",
        "      layerlist.append(nn.Dropout(p)) #adding the dropout to the layer\r\n",
        "      n_in = i #equating n_in with the number of neurons i, so that the next fully connected layer can start with i - 1 neurons.\r\n",
        "\r\n",
        "    #So layers is going to look like this: layers = [192, 96, 48] meaning you want 256 neurons in first layer, then 128 neurons in second layer, then 64. This allows us play around with the values and makes it flexible. \r\n",
        "    layerlist.append(nn.Linear(n_layers[-1], out_size)) #so making the last layer be connected by the last layer and output size\r\n",
        "    self.layers = nn.Sequential(*layerlist) #using sequential to combine the layers from the layerlist so that it can be ordered properly as a NN\r\n",
        "\r\n",
        "  def forward(self, x_categorical, x_continuous):\r\n",
        "    #So this determines the forward propagation with the activation functions we want to use\r\n",
        "\r\n",
        "    # Now we are utilizing the embeddings to pass into our forward method\r\n",
        "    embeddings = [] \r\n",
        "\r\n",
        "    for i,e in enumerate(self.embeds):\r\n",
        "      embeddings.append(e(x_categorical[:,i])) #so we're adding to our embeddingz list for each row and column i in our categorical inputs, x_cat\r\n",
        "\r\n",
        "    x = torch.cat(tensors = embeddings, dim = 1) #so we're concatenating embeddings along dimension 1, meaning all the values we got above for each tensor will be within a single row (i.e. 12(hour) + 1(amorpm) + 4(weekday) all in one row within a single tensor)\r\n",
        "    x = self.emb_drop(x) #adding the drop out layer to our embedded categorical data\r\n",
        "\r\n",
        "    x_cont = self.bn_cont(x_continuous) #normalizing our continuous data\r\n",
        "    x = torch.cat(tensors = [x, x_continuous], dim = 1) #concatenating our categorical and continuous data to be in a single tensor row\r\n",
        "    x = self.layers(x) #passing our continuous and categorical data into our NN, which was made above with Sequential\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLXWvZ4J0R9X",
        "outputId": "38b2ac8a-c6b7-488a-d607-f4decea298c6"
      },
      "source": [
        "model = Model(emb_sizes,  n_continuous = conts.shape[1], out_size = 2, n_layers = [192, 96, 48]) #conts.shape[1] is the number of columns in the continuous tensor, output size is 2 (since we have 2 classes, 0 or 1, which is a binary classification problem), and hidden layers will have 192 then 96 then 48 neurons\r\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(2, 1)\n",
              "    (1): Embedding(14, 7)\n",
              "    (2): Embedding(6, 3)\n",
              "    (3): Embedding(5, 3)\n",
              "    (4): Embedding(12, 6)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.5, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=22, out_features=192, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=192, out_features=96, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=96, out_features=48, bias=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Linear(in_features=48, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1sNmPZn0w_v",
        "outputId": "2187b62e-9acf-4750-9504-161359b76594"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() #so our loss measurement will be based off CrossEntropyLoss since this is a mutually exclusive answer (only 1 target can be correct)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001) #model parameters are just the fully connected layers and we are using Adam optimizer to optimize them\r\n",
        "model.parameters #can see the parameters are just the fully connected layers and we are optimizing them"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Model(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(2, 1)\n",
              "    (1): Embedding(14, 7)\n",
              "    (2): Embedding(6, 3)\n",
              "    (3): Embedding(5, 3)\n",
              "    (4): Embedding(12, 6)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.5, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=22, out_features=192, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=192, out_features=96, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=96, out_features=48, bias=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Linear(in_features=48, out_features=2, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTJpRXDT1pIP",
        "outputId": "21ff9b07-a426-4ba7-a304-2130f6e32b1d"
      },
      "source": [
        "batch_size = 30000 #just going to feed in all the data\r\n",
        "test_size = int(batch_size*0.20) #making our test size 1/3 the batch size\r\n",
        "\r\n",
        "#Our data was shuffled already when we got it, which is why we can do the following. If it wasn't shuffled already, then we'd need to shuffle first before assigning the train test split\r\n",
        "\r\n",
        "categorical_train = cats[:batch_size - test_size] #so take from index 0 to 24000\r\n",
        "categorical_test = cats[batch_size - test_size: batch_size] #take from index 24000 to 30000\r\n",
        "continuous_train = conts[:batch_size - test_size]\r\n",
        "continuous_test = conts[batch_size - test_size: batch_size]\r\n",
        "y_train = y[:batch_size - test_size]\r\n",
        "y_test = y[batch_size - test_size: batch_size]\r\n",
        "\r\n",
        "print(len(categorical_train))\r\n",
        "print(len(categorical_test))\r\n",
        "print(len(continuous_train))\r\n",
        "print(len(continuous_test))\r\n",
        "print(len(y_train))\r\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000\n",
            "6000\n",
            "24000\n",
            "6000\n",
            "24000\n",
            "6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSdvZR_B13VK",
        "outputId": "89c63386-4c77-41ec-a244-a841e6d23c52"
      },
      "source": [
        "import time #Gonna try to keep track of how long it takes to train our model\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "epochs = 500\r\n",
        "\r\n",
        "losses = []\r\n",
        "\r\n",
        "#This for loop trains our NN\r\n",
        "for i in range(epochs):\r\n",
        "  #Forward propagation through our ANN using training data\r\n",
        "  y_pred = model.forward(categorical_train, continuous_train)\r\n",
        "\r\n",
        "  #Calculating loss/error\r\n",
        "  loss = criterion(y_pred, y_train)\r\n",
        "  losses.append(loss)\r\n",
        "  if i%50 == 1:\r\n",
        "    print(f'epoch {i} and loss is: {loss} and time: {(time.time() - start_time)/60}')\r\n",
        "\r\n",
        "  #Backpropagation\r\n",
        "  optimizer.zero_grad() #resetting the gradient on the optimizer so it doesn't accumulate\r\n",
        "  loss.backward() #doing backpropagation off the loss function\r\n",
        "  optimizer.step() #using the optimizer for the back propagation\r\n",
        "\r\n",
        "print(f'Training took {(time.time() - start_time)/60} minutes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 and loss is: 0.7249107956886292 and time: 0.01924690802892049\n",
            "epoch 51 and loss is: 0.49307575821876526 and time: 0.709987465540568\n",
            "epoch 101 and loss is: 0.43053433299064636 and time: 1.3998127261797586\n",
            "epoch 151 and loss is: 0.3932628035545349 and time: 2.1041576266288757\n",
            "epoch 201 and loss is: 0.3546769618988037 and time: 2.797495452562968\n",
            "epoch 251 and loss is: 0.3357846140861511 and time: 3.48924898703893\n",
            "epoch 301 and loss is: 0.3224593698978424 and time: 4.1829642454783125\n",
            "epoch 351 and loss is: 0.3142148554325104 and time: 4.868505966663361\n",
            "epoch 401 and loss is: 0.3092731237411499 and time: 5.556210096677145\n",
            "epoch 451 and loss is: 0.3064259886741638 and time: 6.25267273982366\n",
            "Training took 6.947432510058085 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKQBAdPJ2li4"
      },
      "source": [
        "# **Part 3: Evaluating and Testing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "UwVZvbsX2s63",
        "outputId": "30f8b313-cbd7-4ab8-f78f-e3734d8f18c6"
      },
      "source": [
        "#Plotting our error\r\n",
        "plt.plot(range(epochs),losses)\r\n",
        "plt.ylabel('CrossEntropy Loss')\r\n",
        "plt.xlabel('Epoch') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBi75pxN2uEr",
        "outputId": "e95b36be-143c-45ba-b3c5-b125e422ffde"
      },
      "source": [
        "#This just turns off the backpropagation, so we can use the model for evaluation rather than training. This helps reduce memory usage and computation speed\r\n",
        "with torch.no_grad():\r\n",
        "  y_val = model.forward(categorical_test, continuous_test)\r\n",
        "  loss = criterion(y_val, y_test) #comparing the actual results with the evaluation results\r\n",
        "\r\n",
        "print('Cross Entropy loss =',loss) #average cross entropy loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Entropy loss = tensor(0.3108)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3sU8lAf3C3j",
        "outputId": "76818aff-3c7f-45f9-a3dd-1a25263867e2"
      },
      "source": [
        "rows = 6000\r\n",
        "correct = 0\r\n",
        "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\r\n",
        "for i in range(rows):\r\n",
        "    if y_val[i].argmax().item() == y_test[i]:\r\n",
        "        correct += 1\r\n",
        "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL OUTPUT               ARGMAX  Y_TEST\n",
            "\n",
            "5145 out of 6000 = 85.75% correct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BJxA-vw7KuY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}